{
  "fold1": {
    "micro_precision": 0.8447678447678447,
    "micro_recall": 0.5523334843679203,
    "micro_f1": 0.667945205479452,
    "macro_precision": 0.6423731809697489,
    "macro_recall": 0.36061016668732004,
    "macro_f1": 0.4441603830900556,
    "hamming_loss": 0.018986746874706268,
    "subset_accuracy": 0.9160635398063728,
    "macro_roc_auc": 0.9800147638295739,
    "micro_roc_auc": 0.9834661866420022,
    "macro_pr_auc": 0.6387039114525331,
    "micro_pr_auc": 0.8028337867786196,
    "macro_brier": 0.013533065971905138,
    "macro_ece": 0.004554329641460291,
    "latency_seconds_per_1k": 0.26108580140290333,
    "inference_samples": 10639,
    "inference_time_total": 2.7776918411254883,
    "precision_at_1000": 0.927,
    "recall_at_1000": 0.42002718622564567,
    "hits_at_1000": 927,
    "thresh_toxic": 0.5917261309459222,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.4383591647152038,
    "thresh_threat": 0.9968477940358428,
    "thresh_insult": 0.8154863320986526,
    "thresh_identity_hate": 0.7805702738077093
  },
  "fold1_seed42": {
    "micro_precision": 0.8861915367483296,
    "micro_recall": 0.566566994162039,
    "micro_f1": 0.6912186224268219,
    "macro_precision": 0.8352397378574276,
    "macro_recall": 0.334238982545693,
    "macro_f1": 0.4136274640131596,
    "hamming_loss": 0.018564938116872945,
    "subset_accuracy": 0.9180636064546451,
    "macro_roc_auc": 0.9846800928572389,
    "micro_roc_auc": 0.9873730596317305,
    "macro_pr_auc": 0.6689391884620345,
    "micro_pr_auc": 0.835605335190556,
    "macro_brier": 0.01310276614283455,
    "macro_ece": 0.00457329165668495,
    "latency_seconds_per_1k": 0.2765218198962408,
    "inference_samples": 31915,
    "inference_time_total": 8.825193881988525,
    "precision_at_1000": 0.995,
    "recall_at_1000": 0.14167734586359107,
    "hits_at_1000": 995,
    "thresh_toxic": 0.5611691639344493,
    "thresh_severe_toxic": 0.9369177329685519,
    "thresh_obscene": 0.5906673292495602,
    "thresh_threat": 0.9509417902553249,
    "thresh_insult": 0.8579356015742626,
    "thresh_identity_hate": 0.9691358807231815
  },
  "fold1_seed43": {
    "micro_precision": 0.8704758031720211,
    "micro_recall": 0.613411663562115,
    "micro_f1": 0.719677229553669,
    "macro_precision": 0.8117995769503793,
    "macro_recall": 0.39980267064921504,
    "macro_f1": 0.48076514732875775,
    "hamming_loss": 0.017416053057600918,
    "subset_accuracy": 0.9220742597524675,
    "macro_roc_auc": 0.9855058300610495,
    "micro_roc_auc": 0.9878718937009188,
    "macro_pr_auc": 0.6753659928298673,
    "micro_pr_auc": 0.8414528188679454,
    "macro_brier": 0.01262015140305939,
    "macro_ece": 0.0041530048305586575,
    "latency_seconds_per_1k": 0.27316567966151006,
    "inference_samples": 31915,
    "inference_time_total": 8.718082666397095,
    "precision_at_1000": 0.99,
    "recall_at_1000": 0.14185413383006162,
    "hits_at_1000": 990,
    "thresh_toxic": 0.5862696663392383,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.44232505986390125,
    "thresh_threat": 0.8621947109951237,
    "thresh_insult": 0.7819221847194958,
    "thresh_identity_hate": 0.9742137737223158
  },
  "fold1_seed44": {
    "micro_precision": 0.8976207642393655,
    "micro_recall": 0.5196883261444274,
    "micro_f1": 0.6582657737046176,
    "macro_precision": 0.7920148516194062,
    "macro_recall": 0.32856504775546597,
    "macro_f1": 0.4185642885998055,
    "hamming_loss": 0.02025171027207687,
    "subset_accuracy": 0.9133949553501488,
    "macro_roc_auc": 0.9846928021894,
    "micro_roc_auc": 0.9877991401569309,
    "macro_pr_auc": 0.6575675213193698,
    "micro_pr_auc": 0.8401392433304501,
    "macro_brier": 0.013129059773685116,
    "macro_ece": 0.00436169106833524,
    "latency_seconds_per_1k": 0.2624119297381985,
    "inference_samples": 31915,
    "inference_time_total": 8.374876737594604,
    "precision_at_1000": 0.993,
    "recall_at_1000": 0.13816613329622932,
    "hits_at_1000": 993,
    "thresh_toxic": 0.6501130946481862,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.7839941651688682,
    "thresh_threat": 0.9769737531316451,
    "thresh_insult": 0.9715300683551201,
    "thresh_identity_hate": 0.9751372971248724
  },
  "fold2": {
    "micro_precision": 0.8695652173913043,
    "micro_recall": 0.5155089558759284,
    "micro_f1": 0.6472846955567746,
    "macro_precision": 0.7578530982380602,
    "macro_recall": 0.3526517016253699,
    "macro_f1": 0.4328657666521445,
    "hamming_loss": 0.02014789747446262,
    "subset_accuracy": 0.9124835495393872,
    "macro_roc_auc": 0.9828636291769666,
    "micro_roc_auc": 0.9852074754372111,
    "macro_pr_auc": 0.6240632830834393,
    "micro_pr_auc": 0.8155306217365735,
    "macro_brier": 0.013566736214879948,
    "macro_ece": 0.0049582829369120085,
    "latency_seconds_per_1k": 0.2569025408663591,
    "inference_samples": 10638,
    "inference_time_total": 2.732929229736328,
    "precision_at_1000": 0.948,
    "recall_at_1000": 0.41415465268676277,
    "hits_at_1000": 948,
    "thresh_toxic": 0.6580196413119301,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.4493773936830423,
    "thresh_threat": 0.5,
    "thresh_insult": 0.968974813538416,
    "thresh_identity_hate": 0.9879275873346547
  },
  "fold2_seed42": {
    "micro_precision": 0.8861915367483296,
    "micro_recall": 0.566566994162039,
    "micro_f1": 0.6912186224268219,
    "macro_precision": 0.8352397378574276,
    "macro_recall": 0.334238982545693,
    "macro_f1": 0.4136274640131596,
    "hamming_loss": 0.018564938116872945,
    "subset_accuracy": 0.9180636064546451,
    "macro_roc_auc": 0.9846800928572389,
    "micro_roc_auc": 0.9873730596317305,
    "macro_pr_auc": 0.6689391884620345,
    "micro_pr_auc": 0.835605335190556,
    "macro_brier": 0.01310276614283455,
    "macro_ece": 0.00457329165668495,
    "latency_seconds_per_1k": 0.2670904620022828,
    "inference_samples": 31915,
    "inference_time_total": 8.524192094802856,
    "precision_at_1000": 0.995,
    "recall_at_1000": 0.14167734586359107,
    "hits_at_1000": 995,
    "thresh_toxic": 0.5611691639344493,
    "thresh_severe_toxic": 0.9369177329685519,
    "thresh_obscene": 0.5906673292495602,
    "thresh_threat": 0.9509417902553249,
    "thresh_insult": 0.8579356015742626,
    "thresh_identity_hate": 0.9691358807231815
  },
  "fold2_seed43": {
    "micro_precision": 0.8704758031720211,
    "micro_recall": 0.613411663562115,
    "micro_f1": 0.719677229553669,
    "macro_precision": 0.8117995769503793,
    "macro_recall": 0.39980267064921504,
    "macro_f1": 0.48076514732875775,
    "hamming_loss": 0.017416053057600918,
    "subset_accuracy": 0.9220742597524675,
    "macro_roc_auc": 0.9855058300610495,
    "micro_roc_auc": 0.9878718937009188,
    "macro_pr_auc": 0.6753659928298673,
    "micro_pr_auc": 0.8414528188679454,
    "macro_brier": 0.01262015140305939,
    "macro_ece": 0.0041530048305586575,
    "latency_seconds_per_1k": 0.2933321039485797,
    "inference_samples": 31915,
    "inference_time_total": 9.361694097518921,
    "precision_at_1000": 0.99,
    "recall_at_1000": 0.14185413383006162,
    "hits_at_1000": 990,
    "thresh_toxic": 0.5862696663392383,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.44232505986390125,
    "thresh_threat": 0.8621947109951237,
    "thresh_insult": 0.7819221847194958,
    "thresh_identity_hate": 0.9742137737223158
  },
  "fold2_seed44": {
    "micro_precision": 0.8976207642393655,
    "micro_recall": 0.5196883261444274,
    "micro_f1": 0.6582657737046176,
    "macro_precision": 0.7920148516194062,
    "macro_recall": 0.32856504775546597,
    "macro_f1": 0.4185642885998055,
    "hamming_loss": 0.02025171027207687,
    "subset_accuracy": 0.9133949553501488,
    "macro_roc_auc": 0.9846928021894,
    "micro_roc_auc": 0.9877991401569309,
    "macro_pr_auc": 0.6575675213193698,
    "micro_pr_auc": 0.8401392433304501,
    "macro_brier": 0.013129059773685116,
    "macro_ece": 0.00436169106833524,
    "latency_seconds_per_1k": 0.2822362534327136,
    "inference_samples": 31915,
    "inference_time_total": 9.007570028305054,
    "precision_at_1000": 0.993,
    "recall_at_1000": 0.13816613329622932,
    "hits_at_1000": 993,
    "thresh_toxic": 0.6501130946481862,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.7839941651688682,
    "thresh_threat": 0.9769737531316451,
    "thresh_insult": 0.9715300683551201,
    "thresh_identity_hate": 0.9751372971248724
  },
  "fold3": {
    "micro_precision": 0.8765957446808511,
    "micro_recall": 0.5259574468085106,
    "micro_f1": 0.6574468085106383,
    "macro_precision": 0.8269263204875572,
    "macro_recall": 0.3456171287164836,
    "macro_f1": 0.4369570502592314,
    "hamming_loss": 0.020179231685153853,
    "subset_accuracy": 0.9138935890204926,
    "macro_roc_auc": 0.9823657053118701,
    "micro_roc_auc": 0.9843028781096577,
    "macro_pr_auc": 0.6386721879986299,
    "micro_pr_auc": 0.8098056707083664,
    "macro_brier": 0.014242035064299788,
    "macro_ece": 0.00456157141785958,
    "latency_seconds_per_1k": 0.26425003758900417,
    "inference_samples": 10638,
    "inference_time_total": 2.811091899871826,
    "precision_at_1000": 0.933,
    "recall_at_1000": 0.39702127659574465,
    "hits_at_1000": 933,
    "thresh_toxic": 0.6004145365110806,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.5413014644075429,
    "thresh_threat": 0.7539782991238466,
    "thresh_insult": 0.8785631814208985,
    "thresh_identity_hate": 0.9865385084968558
  },
  "fold3_seed42": {
    "micro_precision": 0.8861915367483296,
    "micro_recall": 0.566566994162039,
    "micro_f1": 0.6912186224268219,
    "macro_precision": 0.8352397378574276,
    "macro_recall": 0.334238982545693,
    "macro_f1": 0.4136274640131596,
    "hamming_loss": 0.018564938116872945,
    "subset_accuracy": 0.9180636064546451,
    "macro_roc_auc": 0.9846800928572389,
    "micro_roc_auc": 0.9873730596317305,
    "macro_pr_auc": 0.6689391884620345,
    "micro_pr_auc": 0.835605335190556,
    "macro_brier": 0.01310276614283455,
    "macro_ece": 0.00457329165668495,
    "latency_seconds_per_1k": 0.27291386661233713,
    "inference_samples": 31915,
    "inference_time_total": 8.71004605293274,
    "precision_at_1000": 0.995,
    "recall_at_1000": 0.14167734586359107,
    "hits_at_1000": 995,
    "thresh_toxic": 0.5611691639344493,
    "thresh_severe_toxic": 0.9369177329685519,
    "thresh_obscene": 0.5906673292495602,
    "thresh_threat": 0.9509417902553249,
    "thresh_insult": 0.8579356015742626,
    "thresh_identity_hate": 0.9691358807231815
  },
  "fold3_seed43": {
    "micro_precision": 0.8704758031720211,
    "micro_recall": 0.613411663562115,
    "micro_f1": 0.719677229553669,
    "macro_precision": 0.8117995769503793,
    "macro_recall": 0.39980267064921504,
    "macro_f1": 0.48076514732875775,
    "hamming_loss": 0.017416053057600918,
    "subset_accuracy": 0.9220742597524675,
    "macro_roc_auc": 0.9855058300610495,
    "micro_roc_auc": 0.9878718937009188,
    "macro_pr_auc": 0.6753659928298673,
    "micro_pr_auc": 0.8414528188679454,
    "macro_brier": 0.01262015140305939,
    "macro_ece": 0.0041530048305586575,
    "latency_seconds_per_1k": 0.2654154435530849,
    "inference_samples": 31915,
    "inference_time_total": 8.470733880996704,
    "precision_at_1000": 0.99,
    "recall_at_1000": 0.14185413383006162,
    "hits_at_1000": 990,
    "thresh_toxic": 0.5862696663392383,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.44232505986390125,
    "thresh_threat": 0.8621947109951237,
    "thresh_insult": 0.7819221847194958,
    "thresh_identity_hate": 0.9742137737223158
  },
  "fold3_seed44": {
    "micro_precision": 0.8976207642393655,
    "micro_recall": 0.5196883261444274,
    "micro_f1": 0.6582657737046176,
    "macro_precision": 0.7920148516194062,
    "macro_recall": 0.32856504775546597,
    "macro_f1": 0.4185642885998055,
    "hamming_loss": 0.02025171027207687,
    "subset_accuracy": 0.9133949553501488,
    "macro_roc_auc": 0.9846928021894,
    "micro_roc_auc": 0.9877991401569309,
    "macro_pr_auc": 0.6575675213193698,
    "micro_pr_auc": 0.8401392433304501,
    "macro_brier": 0.013129059773685116,
    "macro_ece": 0.00436169106833524,
    "latency_seconds_per_1k": 0.2898032549834636,
    "inference_samples": 31915,
    "inference_time_total": 9.249070882797241,
    "precision_at_1000": 0.993,
    "recall_at_1000": 0.13816613329622932,
    "hits_at_1000": 993,
    "thresh_toxic": 0.6501130946481862,
    "thresh_severe_toxic": 0.5,
    "thresh_obscene": 0.7839941651688682,
    "thresh_threat": 0.9769737531316451,
    "thresh_insult": 0.9715300683551201,
    "thresh_identity_hate": 0.9751372971248724
  }
}